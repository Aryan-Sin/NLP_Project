{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fU4jxUe7XUau"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Translite - A Low Resoure Modular Multi-Lingual NLP Translator"
      ],
      "metadata": {
        "id": "DyMLKWK3WKpW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1 - Configuration\n",
        "This is where the datasets will be prepared and configured. User is capable of adding as many languages as they'd like to this. The main requirement will be that datasets must be stored on Kaggle and in the following formats:\n",
        "  - CSV\n",
        "  - Excel\n",
        "  - JSON\n",
        "  - Parquet\n",
        "\n",
        "This can be checked by looking at the **Data Explorer** on the Kaggle page for your dataset and seeing if the files have the extension \".json\", \".csv\", \".xlsx\", or \".parquet\"."
      ],
      "metadata": {
        "id": "32U9cP6vW0Uz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1 - Install Requirements"
      ],
      "metadata": {
        "id": "fU4jxUe7XUau"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLyJc5mfWILI"
      },
      "outputs": [],
      "source": [
        "!pip install ipywidgets pandas kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2 - Load/Create Config"
      ],
      "metadata": {
        "id": "EbjYCSfRY8ln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here you will add your datasets for all of the languages you'd like to translate to English. You will need to add the url to the raw dataset, the name of the column where the English versions are, the name of the column where the non-English versions are stored, and the actual name of the language. It is suggested that you use the export button to save your config when you're done so that you can quickly import again when you return. A sample dataset with Spanish and Italian is available as well."
      ],
      "metadata": {
        "id": "RPsdsOLGeHAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "df = pd.DataFrame(columns=[\n",
        "    \"Kaggle Dataset Name\",\n",
        "    \"Language Name\",\n",
        "    \"English Column Name\",\n",
        "    \"Other Language Column Name\"])\n",
        "\n",
        "def display_table(df):\n",
        "    clear_output(wait=True)\n",
        "    display(ds_uri, lang, eng_col, natv_col)\n",
        "    display(widgets.HBox((add_button, import_button, export_button, clear_button)))\n",
        "    display(df)\n",
        "\n",
        "def add_row(ds_uri, lang, eng_col, natv_col):\n",
        "    global df\n",
        "    new_row = pd.DataFrame([[ds_uri, lang, eng_col, natv_col]], columns=df.columns.tolist())\n",
        "    df = pd.concat([df, new_row], ignore_index=True)\n",
        "    display_table(df)\n",
        "\n",
        "ds_uri = widgets.Text(description=\"Kaggle Dataset Name:\",\n",
        "                      layout=widgets.Layout(width=\"500px\"),\n",
        "                      style=dict(description_width='initial'))\n",
        "lang = widgets.Text(description=\"Language Name:\",\n",
        "                      layout=widgets.Layout(width=\"500px\"),\n",
        "                      style=dict(description_width='initial'))\n",
        "eng_col = widgets.Text(description=\"English Column Name:\",\n",
        "                      layout=widgets.Layout(width=\"500px\"),\n",
        "                      style=dict(description_width='initial'))\n",
        "natv_col = widgets.Text(description=\"Other Language Column Name:\",\n",
        "                      layout=widgets.Layout(width=\"500px\"),\n",
        "                      style=dict(description_width='initial'))\n",
        "add_button = widgets.Button(description=\"Add Row\")\n",
        "import_button = widgets.Button(description=\"Import Dataset\")\n",
        "export_button = widgets.Button(description=\"Export Dataset\")\n",
        "clear_button = widgets.Button(description=\"Clear Table\")\n",
        "\n",
        "def on_import_button_click(b):\n",
        "    uploaded = files.upload()\n",
        "    filename = next(iter(uploaded))\n",
        "    global df\n",
        "    df = pd.read_json(filename)\n",
        "    display_table(df)\n",
        "\n",
        "def on_export_button_click(b):\n",
        "    df.to_json(\"translite_datasets.json\", index=False)\n",
        "    files.download(\"translite_datasets.json\")\n",
        "\n",
        "def on_add_button_click(b):\n",
        "    add_row(ds_uri.value, lang.value, eng_col.value, natv_col.value)\n",
        "    ds_uri.value = \"\"\n",
        "    lang.value = \"\"\n",
        "    eng_col.value = \"\"\n",
        "    natv_col.value = \"\"\n",
        "\n",
        "def on_clear_button_click(b):\n",
        "    global df\n",
        "    df = pd.DataFrame(columns=[\n",
        "        \"Kaggle Dataset Name\",\n",
        "        \"Language Name\",\n",
        "        \"English Column Name\",\n",
        "        \"Other Language Column Name\"])\n",
        "    display_table(df)\n",
        "\n",
        "add_button.on_click(on_add_button_click)\n",
        "import_button.on_click(on_import_button_click)\n",
        "export_button.on_click(on_export_button_click)\n",
        "clear_button.on_click(on_clear_button_click)\n",
        "display_table(df)\n"
      ],
      "metadata": {
        "id": "dNerTjdiXgif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Load Sample (Optional)\n",
        "If you just want to test this script and don't want to curate a list of languages yourself please use this feature to load a sample dataset."
      ],
      "metadata": {
        "id": "LrZ6Ivjrjbau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "raw_config = '{\"Kaggle Dataset Name\":{\"0\":\"devicharith\\/language-translation-englishfrench\",\"1\":\"lonnieqin\\/englishspanish-translation-dataset\"},\"Language Name\":{\"0\":\"French\",\"1\":\"Spanish\"},\"English Column Name\":{\"0\":\"English words\\/sentences\",\"1\":\"english\"},\"Other Language Column Name\":{\"0\":\"French words\\/sentences\",\"1\":\"spanish\"}}'\n",
        "df = pd.DataFrame(json.loads(raw_config))\n",
        "df.to_json(\"translite_datasets.json\", index=False)\n",
        "files.download(\"translite_datasets.json\")"
      ],
      "metadata": {
        "id": "NSO5OkZfkzeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3 - Connect to Kaggle API\n",
        "Datasets for this product will need to be provided from Kaggle, this means that if you need to utilize cutom language translation datasets you must first host them on https://kaggle.com. You need to get a Kaggle API Key as well. To get this go to your account settings page on Kaggle, and click \"Create New API Token\". This will create a file called `kaggle.json` that you will upload here.\n",
        "\n"
      ],
      "metadata": {
        "id": "g8Mtfy7mgrKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir -p ~/.config/kaggle\n",
        "!cp kaggle.json ~/.config/kaggle/\n",
        "!chmod 600 ~/.config/kaggle/kaggle.json\n",
        "\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "api = KaggleApi()\n",
        "api.authenticate()"
      ],
      "metadata": {
        "id": "NkBvfxPPhaPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.4 - Load Datasets from Config\n",
        "This is where you'll test out your config and ensure that you can properly load datasets from it."
      ],
      "metadata": {
        "id": "8E7LahNJfoWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "allowed_types = {\n",
        "    'csv': pd.read_csv,\n",
        "    'json': pd.read_json,\n",
        "    'xlsx': pd.read_excel,\n",
        "    'parquet': pd.read_parquet\n",
        "}\n",
        "\n",
        "for _, dataset in df.iterrows():\n",
        "    if os.path.isdir(dataset[\"Language Name\"]):\n",
        "        continue\n",
        "\n",
        "    print(f\"Loading {dataset['Language Name']}\")\n",
        "    dataset_name = dataset[\"Kaggle Dataset Name\"]\n",
        "    language_name = dataset[\"Language Name\"]\n",
        "\n",
        "    # Get and prep datasets from kaggle\n",
        "    !kaggle datasets download {dataset_name} -d {language_name}\n",
        "    !unzip {dataset_name.split('/')[-1]}.zip -d {language_name}\n",
        "\n",
        "    files = [(f, allowed_types.get(f.split('.')[-1])) for f in os.listdir(language_name)]\n",
        "\n",
        "    curr = pd.DataFrame(columns=[\n",
        "        \"class\", \"english\", \"native\"\n",
        "    ])\n",
        "\n",
        "    # Look for all files in the dir that are readable as datasets and\n",
        "    # reformat them\n",
        "    for f, fn in files:\n",
        "      if fn:\n",
        "        tmp = fn(f\"{language_name}/{f}\")\n",
        "        tmp = tmp.rename(columns={\n",
        "            dataset[\"English Column Name\"]: \"english\",\n",
        "            dataset[\"Other Language Column Name\"]: \"native\"\n",
        "        })\n",
        "        tmp[\"class\"] = language_name\n",
        "        tmp[\"class_int\"] = int(df.apply(lambda row: row[row == 'Spanish'].index, axis=0).iloc[1].values[0])\n",
        "        curr = pd.concat([curr, tmp], ignore_index=True)\n",
        "\n",
        "    curr.to_csv(f\"{language_name}.csv\", index=False)"
      ],
      "metadata": {
        "id": "XQEjDmOZgWyJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}